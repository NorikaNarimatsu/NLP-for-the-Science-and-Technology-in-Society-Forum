{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/norika_machome/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/norika_machome/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/norika_machome/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "df = pd.read_csv(\"summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Tokenized Text</th>\n",
       "      <th>Bigram Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>\\n\\nScience and Technology in Society forum\\n\\...</td>\n",
       "      <td>science technology society forum science techn...</td>\n",
       "      <td>[science, technology, society, forum, science,...</td>\n",
       "      <td>[science_technology, society_forum, science_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>\\nScience and Technology in Society (STS) foru...</td>\n",
       "      <td>science technology society sts forum light sha...</td>\n",
       "      <td>[science, technology, society, sts, forum, lig...</td>\n",
       "      <td>[science_technology, society, sts_forum, light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>\\nScience and Technology in Society (STS) foru...</td>\n",
       "      <td>science technology society sts forum light sha...</td>\n",
       "      <td>[science, technology, society, sts, forum, lig...</td>\n",
       "      <td>[science_technology, society, sts_forum, light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>Science and Technology  in Society (STS) forum...</td>\n",
       "      <td>science technology society sts forum light sha...</td>\n",
       "      <td>[science, technology, society, sts, forum, lig...</td>\n",
       "      <td>[science_technology, society, sts_forum, light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>STS forum 2008       I\\nScience and Technology...</td>\n",
       "      <td>sts forum science technology society sts forum...</td>\n",
       "      <td>[sts, forum, science, technology, society, sts...</td>\n",
       "      <td>[sts_forum, science_technology, society, sts_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                               Text  \\\n",
       "0  1970  \\n\\nScience and Technology in Society forum\\n\\...   \n",
       "1  1970  \\nScience and Technology in Society (STS) foru...   \n",
       "2  1970  \\nScience and Technology in Society (STS) foru...   \n",
       "3  1970  Science and Technology  in Society (STS) forum...   \n",
       "4  1970  STS forum 2008       I\\nScience and Technology...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0  science technology society forum science techn...   \n",
       "1  science technology society sts forum light sha...   \n",
       "2  science technology society sts forum light sha...   \n",
       "3  science technology society sts forum light sha...   \n",
       "4  sts forum science technology society sts forum...   \n",
       "\n",
       "                                      Tokenized Text  \\\n",
       "0  [science, technology, society, forum, science,...   \n",
       "1  [science, technology, society, sts, forum, lig...   \n",
       "2  [science, technology, society, sts, forum, lig...   \n",
       "3  [science, technology, society, sts, forum, lig...   \n",
       "4  [sts, forum, science, technology, society, sts...   \n",
       "\n",
       "                                         Bigram Text  \n",
       "0  [science_technology, society_forum, science_te...  \n",
       "1  [science_technology, society, sts_forum, light...  \n",
       "2  [science_technology, society, sts_forum, light...  \n",
       "3  [science_technology, society, sts_forum, light...  \n",
       "4  [sts_forum, science_technology, society, sts_f...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = pd.to_datetime(df['Year']).dt.year\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to clean, tokenize, and lemmatize the text\n",
    "def clean_and_tokenize(text):\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and stopwords, and lemmatize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    tokens = ['artificial_intelligence' if word == 'ai' else word for word in tokens]\n",
    "    tokens = ['iot' if word == 'internet_of_things' else word for word in tokens]\n",
    "\n",
    "    # Join the tokens back into a string for Cleaned Text\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text, tokens\n",
    "\n",
    "# Apply the cleaning and tokenization function to the 'Text' column\n",
    "df['Cleaned Text'], df['Tokenized Text'] = zip(*df['Text'].apply(clean_and_tokenize))\n",
    "\n",
    "# Train a bigram model\n",
    "phrases = Phrases(df['Tokenized Text'], min_count=5, threshold=10)\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "# Apply the bigram model to transform the tokenized text\n",
    "df['Bigram Text'] = df['Tokenized Text'].apply(lambda x: bigram[x])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to count frequencies\n",
    "def count_frequencies(tokens_list):\n",
    "    all_tokens = [token for tokens in tokens_list for token in tokens]\n",
    "    return Counter(all_tokens)\n",
    "\n",
    "# Count frequencies for tokenized text\n",
    "tokenized_freq = count_frequencies(df['Tokenized Text'])\n",
    "bigram_freq = count_frequencies(df['Bigram Text'])\n",
    "\n",
    "# Get the top 100 words/bigrams\n",
    "top_1000_tokenized = tokenized_freq.most_common(1000)\n",
    "top_1000_bigrams = bigram_freq.most_common(1000)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "top_1000_tokenized_df = pd.DataFrame(top_1000_tokenized, columns=['Word/Bigram', 'Frequency'])\n",
    "top_1000_bigrams_df = pd.DataFrame(top_1000_bigrams, columns=['Word/Bigram', 'Frequency'])\n",
    "\n",
    "# Save to CSV files\n",
    "top_1000_tokenized_df.to_csv('top_1000_tokenized.csv', index=False)\n",
    "top_1000_bigrams_df.to_csv('top_1000_bigrams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Yearly Frequencies:\n",
      "      also  technology  science  need  research  science_technology  society  \\\n",
      "2004     0           0        0     0         0                   0        0   \n",
      "2005     0           0        0     0         0                   0        0   \n",
      "2006     0           0        0     0         0                   0        0   \n",
      "2007     0           0        0     0         0                   0        0   \n",
      "2008     0           0        0     0         0                   0        0   \n",
      "\n",
      "      new  innovation  must  ...  african  language  unique  report  \\\n",
      "2004    0           0     0  ...        0         0       0       0   \n",
      "2005    0           0     0  ...        0         0       0       0   \n",
      "2006    0           0     0  ...        0         0       0       0   \n",
      "2007    0           0     0  ...        0         0       0       0   \n",
      "2008    0           0     0  ...        0         0       0       0   \n",
      "\n",
      "      nutrition  trying  public_private  mankind  accessible  recent_year  \n",
      "2004          0       0               0        0           0            0  \n",
      "2005          0       0               0        0           0            0  \n",
      "2006          0       0               0        0           0            0  \n",
      "2007          0       0               0        0           0            0  \n",
      "2008          0       0               0        0           0            0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Emerging Bigrams:\n",
      "Empty DataFrame\n",
      "Columns: [Bigram]\n",
      "Index: []\n",
      "\n",
      "Disappearing Bigrams:\n",
      "Empty DataFrame\n",
      "Columns: [Bigram]\n",
      "Index: []\n",
      "\n",
      "Gap Bigrams:\n",
      "Empty DataFrame\n",
      "Columns: [Bigram]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams with Drastic Changes:\n",
      "Empty DataFrame\n",
      "Columns: [Bigram, Change Type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identify bigrams with significant changes\n",
    "drastic_change_bigrams = []\n",
    "\n",
    "# Define a threshold for significant change\n",
    "change_threshold = 20  # This can be adjusted based on the data\n",
    "\n",
    "for bigram in bigram_yearly_freq_df.columns:\n",
    "    yearly_freq = bigram_yearly_freq_df[bigram]\n",
    "    max_freq = yearly_freq.max()\n",
    "    min_freq = yearly_freq.min()\n",
    "    \n",
    "    # Check for emergence (start with low frequency, then increase significantly)\n",
    "    if min_freq == 0 and max_freq >= change_threshold:\n",
    "        drastic_change_bigrams.append((bigram, 'emergence'))\n",
    "    \n",
    "    # Check for disappearance (start with high frequency, then drop significantly)\n",
    "    if max_freq > change_threshold and min_freq == 0:\n",
    "        drastic_change_bigrams.append((bigram, 'disappearance'))\n",
    "    \n",
    "    # Check for gaps in the middle of the timeline\n",
    "    if yearly_freq[yearly_freq == 0].any() and (yearly_freq.max() >= change_threshold):\n",
    "        drastic_change_bigrams.append((bigram, 'gap'))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "drastic_change_bigrams_df = pd.DataFrame(drastic_change_bigrams, columns=['Bigram', 'Change Type'])\n",
    "\n",
    "print(\"Bigrams with Drastic Changes:\")\n",
    "print(drastic_change_bigrams_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude unwanted words and bigrams\n",
    "exclude_words = {\n",
    "    'said', 'could', 'many', 'also', 'must', 'may', 'would', 'us', 'one', 'new', \n",
    "    'however', 'important', 'use', 'well', 'including', 'explained', 'noted', \n",
    "    'example', 'order', 'stated', 'often', 'session', 'jp', 'session_chair', 'plenary_session',\n",
    "    'around_world', 'chief_executive', 'executive_officer', 'vice_president', 'also_discussed',\n",
    "    'participants', 'president', 'percent', 'shadows', 'sts_forum', 'director', 'society_forum',\n",
    "    'concurrent_sessions', 'former_president',\n",
    "    'minister', 'issue', 'issues', 'chair', 'please_contact', 'speakers', 'speaker', 'chairman', 'much',\n",
    "    'building_nagatacho', 'opening_remarks'\n",
    "}\n",
    "\n",
    "# Define a function to filter out excluded words and bigrams\n",
    "def filter_excluded_words(bigram_text):\n",
    "    return [word for word in bigram_text if word not in exclude_words]\n",
    "\n",
    "# Apply the exclusion function\n",
    "df['Filtered Bigram Text'] = df['Bigram Text'].apply(filter_excluded_words)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
